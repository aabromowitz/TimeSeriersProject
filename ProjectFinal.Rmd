---
title: "Time Series Project"
author: "Aaron Abromowitz and Alex Thibeaux"
date: "2024-11-16"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Libraries

```{r, message=FALSE, "Load Libraries"}
library(tidyverse)
library(tswge)
library(vars)
library(lubridate)
library(vars)
library(nnfor)
```

# Load Data
```{r Load and wrangle data}

# Variable of Interest - Quarterly from 1/1/63
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/MSPUS.csv"
mhp <- read.csv(file_path, header = TRUE)

# Home ownership rate - Quarterly from 1/1/65
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/RHORUSQ156N.csv"
hor <- read.csv(file_path, header = TRUE)

# Housing units completed - Monthly from 1/1/1968
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/COMPUTSA.csv"
huc <- read.csv(file_path, header = TRUE)

# Supply of new houses - Monthly from 1/1/1963
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/MSACSR.csv"
snh <- read.csv(file_path, header = TRUE)

# House price index - Quarterly from 1/1/1975
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/USSTHPI.csv"
hpi <- read.csv(file_path, header = TRUE)

# Converting Monthly Data to Quarterly Data

# Preserve Monthly format
snh_monthly <- snh
huc_monthly <- huc

# Supply of New Houses Variable 
snh$DATE = as.Date(snh$DATE)
snh$month <- month(snh$DATE)
head(snh)
snh_quarterly <- snh %>%
  filter(snh$month == 1 | snh$month == 4 | snh$month == 7 | snh$month == 10)
summary(snh_quarterly)

# Housing Units Completed Variable
huc$DATE = as.Date(huc$DATE)
huc$month <- month(huc$DATE)
head(huc)
huc_quarterly <- huc %>%
  filter(huc$month == 1 | huc$month == 4 | huc$month == 7 | huc$month == 10)
summary(huc_quarterly)

# Using same time frames, which would be starting at 1975 Q1 and ending at 2024 Q2 (due to hpi data)

# hor observation 41 is 1975 Q1
hor_1975 = hor[41:238,]
hor_1975$DATE <- as.Date(hor_1975$DATE)
summary(hor_1975)

# huc_quarterlly observation 29
huc_1975 = huc_quarterly[29:226,]
summary(huc_1975)

# mhp observation 49 is 1975 Q1
mhp_1975 = mhp[49:246,]
mhp_1975$DATE <- as.Date(mhp_1975$DATE)
summary(mhp_1975)

# snh_quarterly observation 49 is 1975 Q1
snh_1975 = snh_quarterly[49:246,]
summary(snh_1975)

# Housing Price Index variable already from 1975 Q1 - 2024 Q2
hpi$DATE <- as.Date(hpi$DATE)
summary(hpi)

# Create Dataframe
# Combined (Train/Test) Set NOT LOGGED
fed_housing_data_NL = data.frame(Year_Quarter = mhp_1975$DATE, Ownership_Rate = hor_1975$RHORUSQ156N, Housing_Units_Completed = huc_1975$COMPUTSA, Supply_New_Houses = snh_1975$MSACSR, Housing_Price_Index = hpi$USSTHPI, Median_Sales_Price = mhp_1975$MSPUS)

# Combined (Train/Test) Set LOGGED
fed_housing_data = data.frame(Year_Quarter = as.Date(mhp_1975$DATE), Ownership_Rate = hor_1975$RHORUSQ156N, Housing_Units_Completed = huc_1975$COMPUTSA, Supply_New_Houses = snh_1975$MSACSR, Housing_Price_Index = hpi$USSTHPI, Median_Sales_Price = log(mhp_1975$MSPUS))

# Train & Test sets
train = fed_housing_data[1:168,]
test = fed_housing_data[169:198,]

summary(fed_housing_data)
```

# EDA

## Median Housing Sale Price

Our variable of interest is the Median Housing Sale Price. This was quarterly data starting in 1965.

```{r Plot Median Housing Sales Price}
mhp=mhp$MSPUS
plot(ts(mhp/1000, frequency=4,start=c(1965,1)),xlab='Year',ylab='Housing price (in thousands of dollars)')
title(main='Median US Housing Price from 1965')
acf(mhp,ylab='',main='ACF')
x = parzen.wge(mhp)
```

The realization looks like it is increasing linearly. This data could be model with a signal plus noise, with a linear signal.

The realization appears to be non stationary. There is evidence that the data is increasing over time. In addition, the variation appears much higher in later years as in earlier years, showing that variance is increasing over time as well. When modeling, it may be useful to take the logarithm of the data before modeling.

The ACF shows very slowly dampening autocorrelations. The parzen window also shows a very low frequency. This could points to a (1-B) term which could be removed with a high-pass difference filter.

## Home Ownership Rate

We used 4 exogenous variables. The first was home ownership rate. Like the variable of interest, this was quarterly data starting from 1965.

```{r Plot Home Ownership Rate}
hor <- hor$RHORUSQ156N
plot(ts(hor, frequency=4,start=c(1965,1)),xlab='Year',ylab='Percentage')
title(main='Home Ownership Rate from 1965')
acf(hor,ylab='',main='ACF')
x = parzen.wge(hor)
```

Unlike the median house price, the home ownership rate appears to be stationary. There isn’t a linear trend to the data, and the variance seems to be constant over time.

The ACF does show that there are dampening autocorrelations, but not quite at the rate as for median house price. This could point to an ARMA model being appropriate for the home ownership rate.

Similar to median house price, the Parzen Window shows that 0 is a prominent frequency.

## Housing Units Completed

The next exogenous variable is Housing Units Completed. This was a monthly variable, starting from 1968.

```{r Plot Housing Units Complete}
huc <- huc$COMPUTSA
plot(ts(huc, frequency=12,start=c(1968,1)),xlab='Year',ylab='')
title(main='Housing Units Completed from 1968')
acf(huc,ylab='',main='ACF')
x = parzen.wge(huc)
```

This has very similar characteristics to home ownership rate. It’s autocorrelations dampen a little more slowly, but the ACF and Parzen Window look very similar. This variable likewise shows evidence for being stationary.

## Supply of New Houses

```{r Plot Supply of New Houses}
snh <- snh$MSACSR
plot(ts(snh, frequency=12,start=c(1963,1)),xlab='Year',ylab='')
title(main='Supply of New Houses from 1963')
acf(snh,ylab='',main='ACF')
x = parzen.wge(snh)
```

Similar to home ownership rate as well, but with even more quickly dampening autocorrelations. This variable likewise shows evidence for being stationary.

## House Price Index

The next exogenous variable is House Price Index. This was a quarterly variable, starting from 1975.

```{r Plot House Price Index}
hpi <- hpi$USSTHPI
plot(ts(hpi, frequency=4,start=c(1975,1)),xlab='Year',ylab='')
title(main='House Price Index from 1975')
acf(hpi,ylab='',main='ACF')
x = parzen.wge(hpi)
```

The realization has a similar upward trend to the Housing Sale Price. It seems very smooth though, very little variance. Because of the upward trend though, it shows evidence against stationarity.

The ACF and Parzen Window are also similar to those of Housing Sale Price.

Not all the data matches up by date range or by frequency of observation (monthly vs quarterly).  To make everything consistent, we will only use quarterly data going from Q1 1975 to Q2 2024.

# AR(I)MA Model Investigation

## First ARIMA Model

The first model we looked at was an ARIMA model.  From the EDA, we saw that because of the increasing variance, we should look at the log of the Housing Sales Price.  And since the Parzen Window had a prominent peak at 0 and very slowly dampening autocorrelations, we should take the first difference.

```{r Difference Median Housing Price}
log.mhp = fed_housing_data$Median_Sales_Price
mhp = exp(log.mhp)
d.log.mhp = artrans.wge(log.mhp,1)
```

The difference looks more like white noise without an obvious pattern to the ACF.  Next we will try modeling the differenced data as an ARMA model.

```{r ARIMA(p,1,q) p and q estimation}
aic5.wge(d.log.mhp,p=0:6,q=0:2,type='aic')
aic5.wge(d.log.mhp,p=0:6,q=0:2,type='bic')
```

Both the AIC and BIC selection choose p = 1 and q = 2.

We will evaluate our models with a short term horizon of 1 year (4 quarters) and a long term horizon of 5 years (20 quarters).  We calcluated a Rolling Window RMSE for both of those horizons (using the logged data) and calculated an ASE for both of those horizons as well (taking the exponential to get back to the original data).

```{r ARIMA(p,1,q) metrics}
h.short = 4
h.long = 20
l = length(mhp)
est = est.arma.wge(d.log.mhp,p=1,q=2)
f = fore.arima.wge(log.mhp,d=1,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((mhp[(l-h.short+1):l]-exp(f$f))^2)/1e6
ase # 84.37902
f = fore.arima.wge(log.mhp,d=1,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((mhp[(l-h.long+1):l]-exp(f$f))^2)/1e6
ase # 7091.032
```
```{r ARIMA(p,1,q) Rolling Window RMSE 1, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.short,d=1,phi=est$phi,theta=est$theta) # 0.036501
```
```{r ARIMA(p,1,q) Rolling Window RMSE 1 Output}
r$rwRMSE
```
```{r ARIMA(p,1,q) Rolling Window RMSE 2, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.long,d=1,phi=est$phi,theta=est$theta) # 0.13269
```
```{r ARIMA(p,1,q) Rolling Window RMSE 2 Output}
r$rwRMSE
```

For the ARIMA(1,1,2) model we get a short term Rolling Window RMSE of 0.037, a long term Rolling Window RMSE of 0.133, a short term ASE of 84.4 million and a long term ASE of 7.09 billion.

## ARMA Model

As a comparison, we wanted to look a simpler ARMA model.  

```{r ARMA p and q estimation}
aic5.wge(d.log.mhp,p=0:6,q=0:4,type='aic')
aic5.wge(d.log.mhp,p=0:6,q=0:4,type='bic')
```

Both the AIC and BIC selection choose p = 2 and q = 2.

```{r ARMA metrics}
est = est.arma.wge(log.mhp,p=2,q=2)
f = fore.arma.wge(log.mhp,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((mhp[(l-h.short+1):l]-exp(f$f))^2)/1e6
ase # 112.4314
f = fore.arma.wge(log.mhp,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((mhp[(l-h.long+1):l]-exp(f$f))^2)/1e6
ase # 9167.59
```
```{r ARMA Rolling Window RMSE 1, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.short,phi=est$phi,theta=est$theta) # 0.044488
```
```{r ARMA Rolling Window RMSE 1 Output}
r$rwRMSE
```
```{r ARMA Rolling Window RMSE 2, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.long,phi=est$phi,theta=est$theta) # 0.12779
```
```{r ARMA Rolling Window RMSE 2 Output}
r$rwRMSE
```

For the ARMA(2,2) model we get a short term Rolling Window RMSE of 0.044, a long term Rolling Window RMSE of 0.128, a short term ASE of 112.4 million and a long term ASE of 9.17 billion.  Even though this model has a better long term Rolling Window RMSE than the ARIMA model, it did worse in the other metrics.

## ARIMA(p,2,q) model

Looking at the overfit factor table, we can see two prominent 0 frequency roots.  

```{r factor table}
est = est.ar.wge(log.mhp,p=12)
factor.wge(phi=est$phi)
```

Even though the differenced data didn't have slowly dampening autocorrelations and looked liked white noise, the original data had a pretty clear upward trend.  We thought that this warranted investigation into an ARIMA(p,2,q) model.

```{r ARIMA(p,2,q) p and q estimation}
d2.log.mhp = artrans.wge(d.log.mhp,1)
aic5.wge(d.log.mhp,p=0:4,q=0:2,type='aic')
aic5.wge(d.log.mhp,p=0:4,q=0:2,type='bic')
```

Both the AIC and BIC selection choose p = 1 and q = 1.

```{r ARIMA(1,2,1) metrics}
est = est.arma.wge(d2.log.mhp,p=1,q=1)
f = fore.arima.wge(log.mhp,d=2,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((mhp[(l-h.short+1):l]-exp(f$f))^2)/1e6
ase # 162.1383
f = fore.arima.wge(log.mhp,d=2,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((mhp[(l-h.long+1):l]-exp(f$f))^2)/1e6
ase # 6263.556
```
```{r ARIMA(1,2,1) Rolling Window RMSE 1, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.short,d=2,phi=est$phi,theta=est$theta) # 0.049161
```
```{r ARIMA(1,2,1) Rolling Window RMSE 1 Output}
r$rwRMSE
```
```{r ARIMA(1,2,1) Rolling Window RMSE 2, fig.show='hide', results='hide'}
r = roll.win.rmse.wge(log.mhp,h.long,d=2,phi=est$phi,theta=est$theta) # 0.1809277
```
```{r ARIMA(1,2,1) Rolling Window RMSE 2 Output}
r$rwRMSE
```

For the ARIMA(1,2,1) model we get a short term Rolling Window RMSE of 0.049, a long term Rolling Window RMSE of 0.181, a short term ASE of 162.4 million and a long term ASE of 6.26 billion.  Even though this model had the best long term ASE so far, it did worse in the other metrics.

Comparing all three ARMA/ARIMA models, we will choose the ARIMA(1,1,2).  

```{r ARIMA(1,1,2) model characteristics}
est = est.arma.wge(d.log.mhp,p=1,q=2)
f = fore.arima.wge(log.mhp,d=1,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
aic = est$aic
aic # -7.188559
resid = f$resid
xbar=est$xbar
xbar # 0.01211603
vara = est$avar
vara # 0.0007251235
est$phi # 0.6901326
est$theta # 0.9720137 -0.4007360
```

The model (for the log data) can be written as:
(1-B)(1-0.69B)(x_t-0.012) = (1-0.972B+0.401B^2)a_t 
$\sigma$_t^2 = 0.001

Now we will look at residuals to make sure that they are white noise.

```{r ARIMA(1,1,2) residual plots}
plotts.wge(resid)
acf(resid,lag.max=100) 
parzen.wge(resid)
```

They appear to be white noise, and the ACF has very few values above 0.2.  We will run a Ljung-Box test to be sure.

```{r ARIMA(1,2,2) Ljung test}
ljung.wge(resid,K=24,p=1,q=2) # p = 0.2272667, white
ljung.wge(resid,K=48,p=1,q=2) # p = 0.5584003, white
```

The test gives more evidence that the residuals are white noise.  We can also check if they are normally distributed with a histogram.

```{r ARIMA(1,1,2) residual histogram}
hist(resid)
```

We also want to make sure that the ACFs and Parzen Windows generated from ARIMA(1,2,2) models look similar to that of our original data.

```{r ARIMA(1,1,2) generated ACFs and Parzen Windows}
# Multiple ACFs 
set.seed(2)
sims = 10
ACF = acf(log.mhp, plot = "FALSE")
plot(ACF$lag ,ACF$acf , type = "l", lwd = 6)
for( i in 1: sims)
{
  ACF2 = acf(gen.arima.wge(l, phi = est$phi, theta=est$theta,d=1, plot="FALSE"), plot = "FALSE")
  lines(ACF2$lag ,ACF2$acf, lwd = 2, col = "red")
}

# Multiple Parzen 
set.seed(3)
sims = 10
SpecDen = parzen.wge(log.mhp, plot = "FALSE")
plot(SpecDen$freq,SpecDen$pzgram, type = "l", lwd = 6)
for( i in 1: sims)
{
  SpecDen2 = parzen.wge(gen.aruma.wge(l,phi=est$phi, theta=est$theta,d=1, plot ="FALSE"), plot = "FALSE")
  lines(SpecDen2$freq,SpecDen2$pzgram, lwd = 2, col = "red")
}
```

The ACFs don't match up exactly, but have the same slowly dampening behavior.  The Parzen Windows are very close to the original.

# Exogenous Variable Forecasts

In order to use the Exogenous variables in either the MLR or Multi-Variate MLP, it is more realistic to make predictions for them first.  

For error metrics, we will focus on the ASE for short and long term predictions.  This is because we are specifically using these short and long term predictions in future models.

## Home Ownership Rate

The Home Ownership Rate looked like either an ARMA or an ARIMA(p,1,q) might be appropriate.

```{r re-plot Home Ownership Rate}
x = fed_housing_data$Ownership_Rate 
plotts.sample.wge(x)
d = artrans.wge(x,1)
```

We will start with the ARIMA model.

```{r AIC for Home Ownership Rate ARIMA}
aic5.wge(d,p=0:10,q=0:4,type='aic') # 8/1 best
```

The model with the best AIC is p = 8, q = 1.

```{r Home Ownership Rate ARIMA(8,1,1) metrics}
est = est.arma.wge(d,p=8,q=1)
f = fore.arima.wge(x,d=1,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 0.03083697
f = fore.arima.wge(x,d=1,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 2.077416
```

This model has a short term ASE of 0.031 and a long term ASE of 2.08.

Next will compare this to an ARMA model.

```{r AIC for Home Ownership Rate ARMA}
aic5.wge(x,p=0:12,q=0:2,type='aic') # 9/1 best
```

The model it chose had p = 9 and q = 1.

```{r Home Ownership Rate ARMA(9,1) metrics}
est = est.arma.wge(x,p=9,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 0.02468854
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 1.108741
```

This model had better ASE values with 0.025 for short term and 1.11 for long term.  This will be the predictions we use for our MLR and MLP models.

```{r Home Ownership Rate creating forecast predictions}
fed_housing_data_short = fed_housing_data
fed_housing_data_long = fed_housing_data
x = fed_housing_data$Ownership_Rate 
est = est.arma.wge(x,p=9,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
hor.pred.short = f$f
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
hor.pred.long = f$f
fed_housing_data_short$Ownership_Rate[(l-h.short+1):l] = hor.pred.short
fed_housing_data_long$Ownership_Rate[(l-h.long+1):l] = hor.pred.long
```

## Housing Units Completed

The Housing Units Completed variable looked like either an ARMA or an ARIMA(p,1,q) might be appropriate for forecasting.

```{r re-plot Housing Units Completed}
x = fed_housing_data$Housing_Units_Completed 
plotts.sample.wge(x)
d = artrans.wge(x,1)
```

However, this looks like the autocorrelations dampen even less slowly than the Home Ownership Rate, meaning that an ARIMA(p,1,q) model would be even less appropriate.  Since we chose the ARMA model for Home Ownership Rate over the ARIMA model.  We will just focus on the ARMA model for Housing Units Complete.

```{r AIC for Housing Units Completed}
aic5.wge(x,p=0:10,q=0:1,type='aic') # 10/0 best
```

The highest AIC value was for p = 10 and q = 0.

```{r Housing Units Completed AR(10) metrics}
est = est.ar.wge(x,p=10)
f = fore.arima.wge(x,phi=est$phi,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)/1e3
ase # 12.98288
f = fore.arima.wge(x,phi=est$phi,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)/1e3
ase # 8.546039
```

This gives a short term ASE of 13.0k and a long term ASE of 8.5k.  Playing around with some of the other output from the aic5 output showed that an ARMA(9,1) model does slightly better for long term predictions and slightly worse for short term predictions.

```{r Housing Units Completed ARMA(9,1) metrics}
est = est.arma.wge(x,p=9,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)/1e3
ase # 13.44075
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)/1e3
ase # 8.516217
```

We will proceed with the ARMA(9,1) forecast for our future models that use exogenous variables.

```{r Housing Units Completed creating forecast predictions}
x = fed_housing_data$Housing_Units_Completed  
est = est.arma.wge(x,p=9,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
huc.pred.short = f$f
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
huc.pred.long = f$f
fed_housing_data_short$Housing_Units_Completed[(l-h.short+1):l] = huc.pred.short
fed_housing_data_long$Housing_Units_Completed[(l-h.long+1):l] = huc.pred.long
```

## Supply of New Houses

Similar to Housing Units Completed, an ARMA model seems like it would be most appropriate for Supply of New Houses.

```{r re-plot Supply of New Houses}
x = fed_housing_data$Supply_New_Houses 
plotts.sample.wge(x)
d = artrans.wge(x,1)
```

```{r AIC for Supply of New Houses}
aic5.wge(x,p=0:4,q=0:1,type='aic') # 1/0 best
```

The highest AIC value was for p = 1 and q = 0.

```{r Supply of New Houses AR(1) metrics}
est = est.ar.wge(x,p=1)
f = fore.arima.wge(x,phi=est$phi,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 0.6951032
f = fore.arima.wge(x,phi=est$phi,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 3.865913
```

This gives a short term ASE of 13.0k and a long term ASE of 8.5k.  Playing around with some of the other output from the aic5 output showed that an ARMA(9,1) model does slightly better for long term predictions and slightly worse for short term predictions.

```{r Supply of New Houses ARMA(1,1) metrics}
est = est.arma.wge(x,p=1,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 0.4791473
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 3.901133
```

The short term ASE for the ARMA(1,1) is significantly better, but the long term ASE is a little worse.  We will proceed with the ARMA(1,1) model.

```{r Supply of New Houses creating forecast predictions}
x = fed_housing_data$Supply_New_Houses   
est = est.arma.wge(x,p=1,q=1)
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.short,lastn=TRUE)
snh.pred.short = f$f
f = fore.arima.wge(x,phi=est$phi,theta=est$theta,n.ahead=h.long,lastn=TRUE)
snh.pred.long = f$f
fed_housing_data_short$Supply_New_Houses[(l-h.short+1):l] = snh.pred.short
fed_housing_data_long$Supply_New_Houses[(l-h.long+1):l] = snh.pred.long
```

## House price index

```{r re-plot House price index}
x = fed_housing_data$Housing_Price_Index
plotts.sample.wge(x)
d = artrans.wge(x,1)
d2 = artrans.wge(d,1)
dev.off()
parzen.wge(d2)
d3 = artrans.wge(d2,c(0,-1))
dev.off()
acf(d3,lag.max=100)
```

This plot is more similar to the variable of interest, Medium Sale Price.   This means that a linear signal plus noise model could be useful.

However, unlike the other variables, it looked like a single difference wasn't white noise.  Even differencing out the (1-B)^2 still had a 0.25 frequency.  Differencing out that frequency as well looked more like white noise.  So we will look at a signal plus noise model and a (1-B)^2*(1+B^2) model.

```{r House price index signal plus noise AIC}
f = fore.sigplusnoise.wge(x,max.p=0,n.ahead=h.short,lastn=TRUE)
aic5.ar.wge(f$resid,p=0:20) # p = 9
```

The model for the noise with the highest AIC value is p = 9.

```{r House price index signal plus noise ASE}
f = fore.sigplusnoise.wge(x,max.p=9,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 161.2832
f = fore.sigplusnoise.wge(x,max.p=9,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 10014.69
```

The short term ASE is 161 and the long term ASE is 10,014.

```{r House price index signal plus noise metrics}
aic5.wge(d3,p=0:8,q=0:6,type='aic') # 4/5 best
```

It looks like the model with p = 4 and q = 5 had the best AIC.

```{r House price index ARMA(4,5) metrics}
est = est.arma.wge(d3,p=4,q=5)
m = mult.wge(fac1=est$phi,fac2=c(0,-1))
factor.wge(m$model.coef) # looks good
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 16.01932
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 2109.469
```

This model did significantly better with a short term ASE of 16 and a long term ASE of 2,109.  Testing out some of the other values from aic5, found that p = 6 and q = 5 did even better.

```{r House price index ARMA(6,5) metrics}
est = est.arma.wge(d3,p=6,q=5)
m = mult.wge(fac1=est$phi,fac2=c(0,-1))
factor.wge(m$model.coef) # looks good
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.short,lastn=TRUE)
ase = mean((x[(l-h.short+1):l]-f$f)^2)
ase # 14.86637
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.long,lastn=TRUE)
ase = mean((x[(l-h.long+1):l]-f$f)^2)
ase # 558.2356
```

This model had a short term ASE of 15 and a long term ASE of 558.  This is the model we will use to get the forecasts.

```{r House price index creating forecast predictions}
x = fed_housing_data$Housing_Price_Index 
d = artrans.wge(x,1)
d2 = artrans.wge(d,1)
d3 = artrans.wge(d2,c(0,-1))
est = est.arma.wge(d3,p=6,q=5)
m = mult.wge(fac1=est$phi,fac2=c(0,-1))
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.short,lastn=TRUE)
hpi.pred.short = f$f
f = fore.arima.wge(x,d=2,phi=m$model.coef,theta=est$theta,n.ahead=h.long,lastn=TRUE)
hpi.pred.long = f$f
fed_housing_data_short$Housing_Price_Index[(l-h.short+1):l] = hpi.pred.short
fed_housing_data_long$Housing_Price_Index[(l-h.long+1):l] = hpi.pred.long
```

# Signal Plus Noise Model

Our domain knowledge tells us that the positive trend of Median House Price is not random and does have an underlying regression line, but we can run a few tests for linear trend to be sure. We will test for linear trend using simple linear regression with a standard t-test, the Cochran Orcutt Test for Linear Trend, and the WBG Test (Woodward, Bottone, and Gray, 1997). All 3 tests have a p-value below 0.05, rejecting the null hypothesis. The residuals are not white noise yet, so we will fit an ARMA model along with the linear signal.

### Test for linear Trend

```{r Test for linear trend}
# Testing for Linear Trend
t = 1:168
reg = slr.wge(train$Median_Sales_Price)
summary(reg)

# Cochran Orcutt Test for Linear Trend
co_test_msp = co.wge(train$Median_Sales_Price)
co_test_msp$pvalue

# WBG Test
wbg.boot.wge(train$Median_Sales_Price)

# Linear model according to Simple Linear Regression (ignoring correlated errors)
plotts.wge(train$Median_Sales_Price)
fit = reg$b0hat + t*reg$b1hat
points(fit, type = "l")

# Examine Residuals
resid = train$Median_Sales_Price - fit
plot(resid, type = "p")
abline(h=0)

# Quicker way to plot residuals: plot(reg$res, type = "l")
```
### Choosing estimates for the ARMA portion of the Signal Plus Noise Model

After comparing the MLE and Burg estimates on AIC, AICC, and BIC, we determined the MLE estimates were better for all three metrics. All estimates chose an AR(6), with the exception of the MLE estimate using the BIC, which chose an AR(2). We will move forward with the AR(6) model, compare the forecasts visually, and test whether the Average Square Error (ASE) is better for the MLE or the Burg estimates. The MLE estimates have better ASEs, as expected. While there isn't much difference visually between the two, the MLE lower limit (blue line) does contain the actual values, whereas the Burg lower limit (green line) are slightly more narrow and doesn't capture one of the actual values. Given the other evidence for using the MLE estimates, we will move forward with MLE estimates for an AR(6).

```{r Signal Plus Noise models}
# Fit signal plus noise models

# MLE Estimates with AIC
spn.mle.aic = aic.ar.wge(reg$res, type = 'aic', p = 0:7) # ar(6), aic -7.269686

# MLE Estimates with AICC
spn.mle.aicc = aic.ar.wge(reg$res, type = 'aicc', p = 0:7) # ar(6), aicc -6.25239

# MLE Estimates with BIC
spn.mle.bic = aic.ar.wge(reg$res, type = 'bic', p = 0:7) # ar(2), bic -7.147245

# Burg Estimates with AIC
spn.b.aic = aic.burg.wge(reg$res, p = 1:7, type = 'aic') # ar(6), aic -7.278742

# Burg Estimates with AICC
spn.b.aicc = aic.burg.wge(reg$res, p = 1:7, type = 'aicc') # ar(6), aicc -6.261446

# Burg Estimates with BIC
spn.b.bic = aic.burg.wge(reg$res, p = 1:7, type = 'bic') # ar(6), bic -7.157681

# MLE estimates are better for all types: aic, aicc, bic - see comparison table

# Fit with MLE estimates, train/test set
fit.mle.sig = fore.sigplusnoise.wge(train$Median_Sales_Price, linear = TRUE, method = 'mle', freq = 0, max.p = 6, n.ahead = 30)

# Examine residuals
plot(fit.mle.sig$resid)

# ASE with MLE estimates
ASE = mean((test$Median_Sales_Price - fit.mle.sig$f)^2)
ASEexp = mean((exp(test$Median_Sales_Price) - exp(fit.mle.sig$f))^2) # 826.5M

# Fit with burg estimates, train/test set
fit.b.sig = fore.sigplusnoise.wge(train$Median_Sales_Price, linear = TRUE, method = 'burg', freq = 0, max.p = 6, n.ahead = 30)

# Examine residuals
plot(fit.b.sig$resid)

# ASE with Burg estimates
ASE.b = mean((test$Median_Sales_Price - fit.b.sig$f)^2)
ASE.b.exp = mean((exp(test$Median_Sales_Price) - exp(fit.b.sig$f))^2) # 1.11B

# Create table for comparison
labels = c("aic", "aicc", "bic", "ase for AR(6)")
mle.ests = c(spn.mle.aic$value, spn.mle.aicc$value, spn.mle.bic$value, ASE)
burg.ests = c(spn.b.aic$value, spn.b.aicc$value, spn.b.bic$value, ASE.b)
comparison = data.frame(labels,mle.ests,burg.ests)
comparison

# Different Plot
log.mhp = fed_housing_data$Median_Sales_Price
plot(log.mhp, type = 'l')
lines(seq(169,198,1), fit.mle.sig$f, col = "red")
lines(seq(169,198,1), fit.mle.sig$ll, col = "blue")
lines(seq(169,198,1), fit.mle.sig$ul, col = "blue")
lines(seq(169,198,1), fit.b.sig$f, col = "orange")
lines(seq(169,198,1), fit.b.sig$ll, col = "green")
lines(seq(169,198,1), fit.b.sig$ul, col = "green")

```

### Signal Plus Noise using 1 Yr Horizon

The 1 Year Horizon backcast (for the past year) is pretty close to the actual values, with an ASE (on the non-lagged values) around 50M. The residuals appear to be white noise when looking at both the plot and the ACF, indicating this model has explained most of the noise of the data.

```{r Signal Plus Noise with 1 yr Horizon}
# Making sure log.mhp is the correct data
log.mhp = fed_housing_data$Median_Sales_Price

# Fit with MLE estimates, using all data
fit.mle.sig_h4 = fore.sigplusnoise.wge(log.mhp, linear = TRUE, method = 'mle', freq = 0, max.p = 6, n.ahead = 4, lastn = TRUE)

# Different Plot
plot(log.mhp, type = 'l')
lines(seq(195,198,1), fit.mle.sig_h4$f, col = "red")
lines(seq(195,198,1), fit.mle.sig_h4$ll, lty = 3, col = "blue")
lines(seq(195,198,1), fit.mle.sig_h4$ul, lty = 3, col = "blue")

# Zoomed In Plot
plot(log.mhp[149:198], type = 'l', ylim = c(12.3, 13.2), main = "1 Year Forecast for Signal Plus Noise Model")
lines(seq(47,50,1), fit.mle.sig_h4$f, col = "red")
lines(seq(47,50,1), fit.mle.sig_h4$ll, lty = 3, col = "blue")
lines(seq(47,50,1), fit.mle.sig_h4$ul, lty = 3, col = "blue")

# ASE with MLE estimates
ASE.h4 = mean((log.mhp[195:198] - fit.mle.sig_h4$f)^2)
ASEexp.h4 = mean((exp(log.mhp[195:198]) - exp(fit.mle.sig_h4$f))^2)
ASEexp.h4 # 50.92M

# Examine residuals
plot(fit.mle.sig_h4$resid)
plotts.sample.wge(fit.mle.sig_h4$resid)
acf(fit.mle.sig_h4$resid)
ljung.wge(fit.mle.sig_h4$resid, p = 6, q = 0, K = 48)
```
### Signal Plus Noise using 5 Yr Horizon

The 5 Year Horizon backcast (for the past 5 years) is pretty close to the actual values, with an ASE (on the non-lagged values) around 1.1B. The residuals appear to be white noise when looking at both the plot and the ACF, indicating this model has explained most of the noise of the data.

```{r Signal plus noise with 5 yr horizon}
# Making sure log.mhp is the correct data
log.mhp = fed_housing_data$Median_Sales_Price

# Fit with MLE estimates, using all data
fit.mle.sig_h20 = fore.sigplusnoise.wge(log.mhp, linear = TRUE, method = 'mle', freq = 0, max.p = 6, n.ahead = 20, lastn = TRUE)

# Different Plot
plot(log.mhp, type = 'l')
lines(seq(179,198,1), fit.mle.sig_h20$f, col = "red")
lines(seq(179,198,1), fit.mle.sig_h20$ll, lty = 3, col = "blue")
lines(seq(179,198,1), fit.mle.sig_h20$ul, lty = 3, col = "blue")

# Zoomed In
plot(log.mhp[149:198], type = 'l', ylim = c(12.3, 13.2), main = "1 Year Forecast for Signal Plus Noise Model")
lines(seq(31,50,1), fit.mle.sig_h20$f, col = "red")
lines(seq(31,50,1), fit.mle.sig_h20$ll, lty = 3, col = "blue")
lines(seq(31,50,1), fit.mle.sig_h20$ul, lty = 3, col = "blue")

# ASE with MLE estimates
ASE.h20 = mean((log.mhp[179:198] - fit.mle.sig_h20$f)^2)
ASEexp.h20 = mean((exp(log.mhp[179:198]) - exp(fit.mle.sig_h20$f))^2)
ASEexp.h20 # 1.1B

# Examine residuals
plot(fit.mle.sig_h20$resid)
plotts.sample.wge(fit.mle.sig_h20$resid)
acf(fit.mle.sig_h20$resid)
ljung.wge(fit.mle.sig_h20$resid, p = 6, q = 0, K = 48)
```
## Rolling Window RMSE for SPN

To compare this model with other models, we will use code that Aaron has written to create a rolling window that measures RMSE for the model. We will use the MLE estimates for p values of 1-6 to assure ourselves that an AR(6) is the best AR model to accompany the signal. The average RMSE for all 1 year windows (4 quarters) is 0.0326, and the average RMSE for all 5 year windows (20 quarters) is 0.07595. 

```{r Rolling Window RMSE, error = F}
# Aaron's Rolling Window RMSE Code

# If you wanted to use all the fore.sigplusnoise.wge parameters, it would look something like this:
series = log.mhp
horizon = 12
linear = TRUE
method = "mle"
freq=0
max.p=5

# Rolling Window for 1 Year Horizon with MLE
horizon = 4
method = "mle"
source("functions_Aaron.R")
mle.p1h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=1) # 0.03564353
mle.p2h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=2) # 0.03547613
mle.p3h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=3) # 0.03495764
mle.p4h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=4) # 0.03326752
mle.p5h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=5) # 0.03261551
mle.p6h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=6) # 0.03259507
mle.p7h4 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=7) # 0.03259507

# Rolling Window for 5 Year Horizon  with MLE
horizon = 20
source("functions_Aaron.R")
mle.p1h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=1) # 0.08107048
mle.p2h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=2) # 0.08065467
mle.p3h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=3) # 0.07973718
mle.p4h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=4) # 0.07797091
mle.p5h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=5) # 0.07669397
mle.p6h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=6) # 0.0759512
mle.p7h20 = roll.win.rmse.linplusnoise.ada(series, horizon, max.p=7) # 0.0759512
```

## Evaluating Models

We will evaluate the model by comparing the ACFs and the Spectral Densities for the same model on generated signal plus noise data. The loop given in class for Unit 11 does not work with signal plus noise generated realizations because the output includes the AR portion of the model regardless of whether plot = TRUE or FALSE. Thus, we will generate 10 different realizations and then take the ACFs and Spectral Densities of all 10 objects. The 

```{r Ten generated realizations, include = FALSE }

# 10 generated realizations 
# Rename variable in working RMD that was not carried over to final RMD:
fit.mle.sig_notTT = fit.mle.sig

spn.mle.ar6.1 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.2 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.3 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.4 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.5 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.6 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.7 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.8 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.9 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)
spn.mle.ar6.10 = gen.sigplusnoise.wge(n=198, b0 = fit.mle.sig_notTT$b0hat, 
                                   b1 = fit.mle.sig_notTT$b1hat,
                                   phi=fit.mle.sig_notTT$phi.z, 
                                   vara = fit.mle.sig_notTT$wnv, plot = F)

ten.generated = list(spn.mle.ar6.1, spn.mle.ar6.2, spn.mle.ar6.3, spn.mle.ar6.4, spn.mle.ar6.5, spn.mle.ar6.6, spn.mle.ar6.7, spn.mle.ar6.8, spn.mle.ar6.9, spn.mle.ar6.10)

# ten.generated[[1]]
# parzen.wge(ten.generated[[1]])

```

```{r Comparing ACFs and Spectral Densities}
# Compare Spectral Densities
sims = 10
SpecDen = parzen.wge(log.mhp, plot = FALSE)
plot(SpecDen$freq,SpecDen$pzgram, type = "l", lwd = 3)

for( i in 1: sims)
{
   SpecDen2 = parzen.wge(ten.generated[[i]], plot = FALSE)
   lines(SpecDen2$freq,SpecDen2$pzgram, lwd = 2, col = "red")
}

#Compare ACFs
sims = 10
ACF = acf(log.mhp, plot = "FALSE")
plot(ACF$lag ,ACF$acf , type = "l", lwd = 4)

for( i in 1: sims)
{
   ACF2 = acf(ten.generated[[i]], plot = "FALSE")
   lines(ACF2$lag ,ACF2$acf, lwd = 1, col = "red")
}
```

## Model Choice

While the burg estimates had a lower AIC than the MLE estimates, the MLE method of forecasting had better ASE and better rolling window RMSE for all three forecasts (1 yr, 3 yr, and 5 yr)

Our final Signal Plus Noise Model is Xt = 10.871 + .011t + zt, where (1 - .716B - .367B2 - 0.137B3 + 0.062B4 + .076B5 + .118B5)Zt with sigma2 = 0.0006929526

Wording: 

In 1 year, we are 95% confident that the median home sale price will be between $387,759 (e^12.86814) and $468,321 (e^13.05691). Our best estimate is $426,142 (e^12.96253).

In 5 years, we are 95% confident that the median home sale price will be between $419,048 (e^12.94574) and $669,482 (e^13.41426). Our best estimate is $529,665 (e^13.18).

```{r Model Choice}

# Fit with MLE estimates, using all data, forecasting ahead 1 year
fit.mle.sig_h4_ahead = fore.sigplusnoise.wge(log.mhp, linear = TRUE, method = 'mle', freq = 0, max.p = 6, n.ahead = 4, lastn = FALSE)

# Fit with MLE estimates, using all data, forecasting ahead 5 years
fit.mle.sig_h20_ahead = fore.sigplusnoise.wge(log.mhp, linear = TRUE, method = 'mle', freq = 0, max.p = 6, n.ahead = 20, lastn = FALSE)

# Checking if models all have same intercept, slope, and phis
fit.mle.sig_notTT$b0hat == fit.mle.sig_h4_ahead$b0hat
fit.mle.sig_notTT$b1hat == fit.mle.sig_h4_ahead$b1hat
fit.mle.sig_notTT$phi.z == fit.mle.sig_h4_ahead$phi.z

# Model Coefficients
fit.mle.sig_notTT$phi.z
fit.mle.sig_notTT$b0hat
fit.mle.sig_notTT$b1hat
fit.mle.sig_notTT$wnv

# Confidence Intervals

# 1 Year
fit.mle.sig_h4_ahead$ll[4]
fit.mle.sig_h4_ahead$ul[4]
fit.mle.sig_h4_ahead$f[4]

# 5 Years
fit.mle.sig_h20_ahead$ll[20]
fit.mle.sig_h20_ahead$ul[20]
fit.mle.sig_h20_ahead$f[20]
```

# Multi-variate Models

We will try out an MLR model with lag and a VAR model that predicts all variables at the same time.  The exogenous predictions we made previously will be used for the MLR Model.

## MLR Model

We will first start by looking at the lag plots for the four exogenous variables.

```{r MLR lag plots}
x = fed_housing_data
l = ccf(x$Median_Sales_Price,x$Ownership_Rate,lag.max=80)
which.max(l$acf)
l$acf[20] # 0.3090685
l$lag[20] # 0
l = ccf(x$Median_Sales_Price,x$Housing_Units_Completed,lag.max=80)
which.max(l$acf)
l$acf[150] # 0.263895
l$lag[150] # 69, 21 seemed alright
l = ccf(x$Median_Sales_Price,x$Supply_New_Houses,lag.max=60)
which.min(l$acf)
l$acf[70] # -0.2592145
l$lag[70] # 9
l = ccf(x$Median_Sales_Price,x$Housing_Price_Index,lag.max=60)
which.max(l$acf)
l$acf[61] # 0.933195
l$lag[61] # 0
```

It looks like Ownership Rate has a lag of 0, Housing Units Completed has a lag of 21, Supply of New Houses has a lag of 9, and Housing Price Index has a lag of 0.

What does a model with these 4 lagged variables look like.

```{r MLR 4 lagged variables}
x.short = fed_housing_data_short
x.long = fed_housing_data_long
x$Year_Quarter = c()
x.short$Year_Quarter = c()
x.long$Year_Quarter = c()
l = length(x$Median_Sales_Price)
t=1:l
t.train.short= 1:(l-h.short)
t.test.short=(l-h.short+1):l
t.train.long= 1:(l-h.long)
t.test.long=(l-h.long+1):l
x$Housing_Units_Completed_l21 = dplyr::lag(x$Housing_Units_Completed,21)
x$Supply_New_Houses_l9 = dplyr::lag(x$Supply_New_Houses,9)
x.short$Housing_Units_Completed_l21 = dplyr::lag(x.short$Housing_Units_Completed,21)
x.short$Supply_New_Houses_l9 = dplyr::lag(x.short$Supply_New_Houses,9)
x.long$Housing_Units_Completed_l21 = dplyr::lag(x.long$Housing_Units_Completed,21)
x.long$Supply_New_Houses_l9 = dplyr::lag(x.long$Supply_New_Houses,9)
ksfit = lm(x$Median_Sales_Price~x$Ownership_Rate+x$Housing_Units_Completed_l21+x$Supply_New_Houses_l9+x$Housing_Price_Index+t)
summary(ksfit)
AIC(ksfit) # -454.2937
```

The Ownership rate variable didn't have a very high p value, so it wasn't significant in the model.  Let's see what happens when it is removed.

```{r MLR 3 lagged variables}
ksfit = lm(x$Median_Sales_Price~x$Housing_Units_Completed_l21+x$Supply_New_Houses_l9+x$Housing_Price_Index+t)
summary(ksfit)
AIC(ksfit) # -456.0482
```

In this model, all the variables are significant.  The AIC value is slightly lower as well.  We will now determine how to model the residuals using an ARMA model.

```{r MLR ARMA}
aic5.wge(ksfit$residuals,p=0:4,q=0:2,type='aic') # best 2/0
```

The model with the best AIC is an AR(2).

```{r MLR ASEs}
fit=arima(x.short$Median_Sales_Price[t.train.short],order=c(2,0,0),xreg=cbind(t.train.short,x.short$Housing_Units_Completed_l21[t.train.short],x.short$Supply_New_Houses_l9[t.train.short],x.short$Housing_Price_Index[t.train.short]))
preds = predict(fit,newxreg = data.frame(t=t.test.short,Housing_Units_Completed_l21=x.short$Housing_Units_Completed_l21[t.test.short],Supply_New_Houses_l9=x.short$Supply_New_Houses_l9[t.test.short],Housing_Price_Index=x.short$Housing_Price_Index[t.test.short]))
ase = mean((fed_housing_data_NL$Median_Sales_Price[t.test.short]-exp(preds$pred))^2)/1e6
ase # 588.675
plot(seq(1,l,1),x.short$Median_Sales_Price,type="b")
points(seq((l-h.short+1),l,1),preds$pred,type="b",pch=15,col="blue")
fit=arima(x.long$Median_Sales_Price[t.train.long],order=c(2,0,0),xreg=cbind(t.train.long,x$Housing_Units_Completed_l21[t.train.long],x$Supply_New_Houses_l9[t.train.long],x$Housing_Price_Index[t.train.long]))
preds = predict(fit,newxreg = data.frame(t=t.test.short,Housing_Units_Completed_l21=x.long$Housing_Units_Completed_l21[t.test.long],Supply_New_Houses_l9=x.long$Supply_New_Houses_l9[t.test.long],Housing_Price_Index=x.long$Housing_Price_Index[t.test.long]))
ase = mean((fed_housing_data_NL$Median_Sales_Price[t.test.long]-exp(preds$pred))^2)/1e6
ase # 1431.873
plot(seq(1,l,1),x.long$Median_Sales_Price,type="b")
points(seq((l-h.long+1),l,1),preds$pred,type="b",pch=15,col="blue")
```

The short term ASE is 589 M and the long term ASE is 1.4 B.

## VAR Model

```{r VAR AIC}
x = fed_housing_data
x$Year_Quarter = c()
VARselect(x,lag.max=16,type="both",season=NULL,exogen=NULL) # lag = 4
```

The model with lag = 4 was chosen.   

```{r VAR ASEs}
fit = VAR(x,p=4,type='both') 
summary(fit) # trend and const were significant, but only lag up to 2 for variable of interest, huc not very predictive
preds=predict(fit,n.ahead=h.short)
ase = mean((fed_housing_data_NL$Median_Sales_Price[(l-h.short+1):l]-exp(preds$fcst$Median_Sales_Price[,1]))^2)/1e6
ase # 46.3595
plot(seq(1,l,1),x$Median_Sales_Price,type="b")
points(seq(l-h.short+1,l,1),preds$fcst$Median_Sales_Price[1:h.short,1],type="b",pch=15,col="blue")
fanchart(preds)
preds=predict(fit,n.ahead=h.long)
ase = mean((fed_housing_data_NL$Median_Sales_Price[(l-h.long+1):l]-exp(preds$fcst$Median_Sales_Price[,1]))^2)/1e6
ase # 3499.949
plot(seq(1,l,1),x$Median_Sales_Price,type="b")
points(seq(l-h.long+1,l,1),preds$fcst$Median_Sales_Price[1:h.long,1],type="b",pch=15,col="blue")
fanchart(preds)
```

The VAR model has a very small short term ASE of 46.4 M.  This is even smaller than the signal plus noise model.  However, its long term ASE is larger than the MLR model.

# Neural Networks

We investigated 3 Neural Nets for predictions: Multilayer Perceptron (MLP), Long Short-Term Memory(LSTM), and Temporal Fusion Transformer (TFT).

## MLP

## LSTM

LSTMs are a type of Recurrent Neural Network (RNN) that have shown success with Time Series data.

The LSTM was created in Python.  The code is below.

```{python python code, eval=FALSE}
import torch
import torch.nn as nn
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from sklearn.preprocessing import MinMaxScaler
import numpy as np
import random

class TimeSeriesDataset(Dataset):
    def __init__(self, data, sequence_length):
        self.data = torch.FloatTensor(data)
        self.sequence_length = sequence_length

    def __len__(self):
        return len(self.data) - self.sequence_length

    def __getitem__(self, idx):
        return (
            self.data[idx:idx+self.sequence_length],
            self.data[idx+self.sequence_length]
        )

class LSTM(nn.Module):
    def __init__(self, input_size, hidden_size, num_layers):
        super(LSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        
        self.lstm = nn.LSTM(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            batch_first=True
        )
        
        self.fc = nn.Linear(hidden_size, 1)
    
    def forward(self, x):
        # Initialize hidden state with zeros
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        # Initialize cell state
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(x.device)
        
        # Forward propagate LSTM
        out, _ = self.lstm(x, (h0, c0))
        
        # Decode the hidden state of the last time step
        out = self.fc(out[:, -1, :])
        return out

def train_model(model, train_loader, criterion, optimizer, num_epochs):
    model.train()
    for epoch in range(num_epochs):
        total_loss = 0
        for batch_x, batch_y in train_loader:
            batch_x = batch_x.unsqueeze(-1) # Ensure batch_x is 3-D: (batch_size, sequence_length, input_size)
            optimizer.zero_grad()
            outputs = model(batch_x)
            loss = criterion(outputs, batch_y.unsqueeze(1))
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        
        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {total_loss/len(train_loader):.4f}')

# After evaluation
def save_results_to_csv(predictions, actuals, ase, horizon_type="short"):
    results_df = pd.DataFrame({
        'Prediction': predictions,
        'Actual': actuals,
        'Error': [pred - act for pred, act in zip(predictions, actuals)]
    })
    
    # Add summary statistics
    summary_df = pd.DataFrame({
        'Metric': ['ASE'],
        'Value': [ase]
    })
    
    # Save to CSV files
    results_df.to_csv(f'predictions_{horizon_type}_term.csv', index=True)
    summary_df.to_csv(f'metrics_{horizon_type}_term.csv', index=False)

# Set seeds for reproducibility
torch.manual_seed(42)
np.random.seed(42)
random.seed(42)
if torch.cuda.is_available():
    torch.cuda.manual_seed(42)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

# Load and preprocess your data
df = pd.read_csv('https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/MSPUS.csv')
# import pdb
#pdb.set_trace()
data = df['MSPUS'].values[49:246]  # Select rows 49 through 245 inclusive

# After loading data but before normalization
data = np.log(data)  # Apply log transformation

# After loading data but before creating datasets
# Initialize the scaler
scaler = MinMaxScaler()
data_normalized = scaler.fit_transform(data.reshape(-1, 1)).flatten()

# Define parameters
# sequence_length = 10
sequence_length = 8
# sequence_length = 5
hidden_size = 64
# hidden_size = 128
num_layers = 2
# num_layers = 3
batch_size = 32
# batch_size = 16
num_epochs = 100
learning_rate = 0.01
# learning_rate = 0.005
h_short = 4
h_long = 20

# Create dataset and dataloader
# dataset = TimeSeriesDataset(data, sequence_length)
# train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

# Split data into train and test
train_data = data_normalized[:-h_short]  # All data except last h_short entries
test_data = data_normalized[-sequence_length-h_short:]  # Last sequence_length + h_short entries

# Create datasets and dataloaders
train_dataset = TimeSeriesDataset(train_data, sequence_length)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataset = TimeSeriesDataset(test_data, sequence_length)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)

# Initialize model, criterion, and optimizer
model = LSTM(input_size=1, hidden_size=hidden_size, num_layers=num_layers)
# model = LSTM(input_size=1, hidden_size=hidden_size, num_layers=num_layers, dropout=0.2)
criterion = nn.MSELoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)

# Train the model
train_model(model, train_loader, criterion, optimizer, num_epochs)

# Add evaluation mode
def evaluate_model(model, test_loader):
    model.eval()
    predictions = []
    actuals = []
    total_se = 0  # Initialize before the loop
    n = 0  # Initialize before the loop
    with torch.no_grad():
        for batch_x, batch_y in test_loader:
            batch_x = batch_x.unsqueeze(-1)  # Add this line to ensure 3D input
            output = model(batch_x)
            # Denormalize predictions and actuals
            pred = scaler.inverse_transform(output.numpy())[0][0]
            actual = scaler.inverse_transform(batch_y.numpy().reshape(-1, 1))[0][0]
            predictions.append(pred)
            actuals.append(actual)
            # predictions.append(output.item())
            # actuals.append(batch_y.item())

            # Then un-log transform
            pred = np.exp(pred)
            actual = np.exp(actual)

            # Calculate squared error for this prediction
            se = (pred - actual) ** 2
            total_se += se
            n += 1
            
    ase = total_se / 1e6 / n if n > 0 else 0
    return predictions, actuals, ase
    # return predictions, actuals

# Evaluate on test data
# predictions, actuals = evaluate_model(model, test_loader)
predictions, actuals, ase = evaluate_model(model, test_loader)
print("\nTest Results for short term prediction:")
for i, (pred, actual) in enumerate(zip(predictions, actuals)):
    print(f"Prediction {i+1}: {pred:.2f}, Actual: {actual:.2f}")
print(f"\nAverage Squared Error: {ase:,.2f}")

# Save results
save_results_to_csv(predictions, actuals, ase, "short")

# Also do it with the long term evaluation
train_data = data_normalized[:-h_long]  # All data except last h_long entries
test_data = data_normalized[-sequence_length-h_long:]  # Last sequence_length + h_long entries
train_dataset = TimeSeriesDataset(train_data, sequence_length)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
test_dataset = TimeSeriesDataset(test_data, sequence_length)
test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)
train_model(model, train_loader, criterion, optimizer, num_epochs)
predictions, actuals, ase = evaluate_model(model, test_loader)
print("\nTest Results for long term prediction:")
for i, (pred, actual) in enumerate(zip(predictions, actuals)):
    print(f"Prediction {i+1}: {pred:.2f}, Actual: {actual:.2f}")
print(f"\nAverage Squared Error: {ase:,.2f}")
save_results_to_csv(predictions, actuals, ase, "long")
```

The short term prediction was the following:

```{r LSTM short term predictions}
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/LSTM_predictions_short_term.csv"
pred <- read.csv(file_path, header = TRUE)
pred
x = fed_housing_data$Median_Sales_Price
l = length(x)
plot(seq(1,l,1),x,type="b")
points(seq(l-h.short+1,l,1),pred$Prediction,type="b",pch=15,col="blue")
```

The short term ASE was 81.8 M.  This was slightly better than the ARIMA model.  Note that it is like our other ASEs, where it compares to the unlogged, original Medium Sales Prices.

```{r LSTM short term ASE}
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/LSTM_metrics_short_term.csv"
ase <- read.csv(file_path, header = TRUE)
ase
```

The long term prediction was the following:

```{r LSTM long term predictions}
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/LSTM_predictions_long_term.csv"
pred <- read.csv(file_path, header = TRUE)
pred
plot(seq(1,l,1),x,type="b")
points(seq(l-h.long+1,l,1),pred$Prediction,type="b",pch=15,col="blue")
```

The long term ASE was 149 M.  This was an order of magnitude better than the Signal Plus Noise model, which had the best long term ASE so far.  And the plot of the predictions (of the logged data) vs the actual values seems to line up almost exactly.

```{r LSTM long term ASE}
file_path = "https://raw.githubusercontent.com/aabromowitz/TimeSeriersProject/refs/heads/main/LSTM_metrics_long_term.csv"
ase <- read.csv(file_path, header = TRUE)
ase
```

